{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(\n",
    "        self, min_word_length: int = 3, custom_stopwords: Optional[List[str]] = None\n",
    "    ):\n",
    "        self.min_word_length = min_word_length\n",
    "        self.stopwords = set(\n",
    "            custom_stopwords\n",
    "            or [\n",
    "                \"the\",\n",
    "                \"a\",\n",
    "                \"an\",\n",
    "                \"and\",\n",
    "                \"or\",\n",
    "                \"but\",\n",
    "                \"in\",\n",
    "                \"on\",\n",
    "                \"at\",\n",
    "                \"to\",\n",
    "                \"for\",\n",
    "                \"of\",\n",
    "                \"with\",\n",
    "                \"by\",\n",
    "                \"from\",\n",
    "                \"up\",\n",
    "                \"about\",\n",
    "                \"into\",\n",
    "                \"over\",\n",
    "                \"after\",\n",
    "                \"is\",\n",
    "                \"are\",\n",
    "                \"was\",\n",
    "                \"were\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        text = (\n",
    "            unicodedata.normalize(\"NFKD\", str(text))\n",
    "            .encode(\"ascii\", \"ignore\")\n",
    "            .decode(\"utf-8\")\n",
    "        )\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_patterns(self, text: str) -> str:\n",
    "        patterns = [\n",
    "            r\"<[^>]+>\",  # HTML tags\n",
    "            r\"https?://\\S+|www\\.\\S+\",  # URLs\n",
    "            r\"\\S+@\\S+\",  # Email addresses\n",
    "            r\"\\b\\d+\\b\",  # Numeric tokens\n",
    "            r\"[^\\w\\s]\",  # Punctuation\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, \" \", text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "\n",
    "        text = self.normalize_text(text)\n",
    "        text = self.remove_patterns(text)\n",
    "\n",
    "        words = text.split()\n",
    "        cleaned_words = [\n",
    "            word\n",
    "            for word in words\n",
    "            if word not in self.stopwords and len(word) >= self.min_word_length\n",
    "        ]\n",
    "\n",
    "        return \" \".join(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/processed/merged_news.csv')\n",
    "\n",
    "# Print column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cleaner\n",
    "cleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean only text column\n",
    "df['cleaned_text'] = df['text'].apply(cleaner.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "df.to_csv('../data/processed/cleaned_news.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
